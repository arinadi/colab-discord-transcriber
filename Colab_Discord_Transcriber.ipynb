{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arinadi/colab-discord-transcriber/blob/main/Colab_Discord_Transcriber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üöÄ Run Transcription Bot\n",
        "# @markdown Configure all bot parameters here. Hover over a setting for more information provided in the code comments.\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# SECTION 1: PRE-FLIGHT CHECKS & CONFIGURATION\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "# --- 1.1. üîë Load Secrets from Colab (PRIORITY 1) ---\n",
        "from google.colab import userdata, runtime\n",
        "try:\n",
        "    DISCORD_BOT_TOKEN = userdata.get('DISCORD_BOT_TOKEN')\n",
        "    DISCORD_WEBHOOK_URL = userdata.get('DISCORD_WEBHOOK_URL')\n",
        "    DISCORD_CHANNEL_ID = userdata.get('DISCORD_CHANNEL_ID')\n",
        "    if not all([DISCORD_BOT_TOKEN, DISCORD_WEBHOOK_URL, DISCORD_CHANNEL_ID]):\n",
        "        raise ValueError(\"Ensure all secrets (DISCORD_BOT_TOKEN, DISCORD_WEBHOOK_URL, DISCORD_CHANNEL_ID) are set in Colab Secrets.\")\n",
        "    print(\"‚úÖ Secrets loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERROR: Failed to load secrets: {e}\")\n",
        "    raise SystemExit(\"Execution stopped due to missing secrets.\")\n",
        "\n",
        "\n",
        "# --- 1.2. üõ†Ô∏è Bot Configuration (Tunable Parameters) ---\n",
        "# @markdown ---\n",
        "# @markdown ### ü§ñ Model & Transcription Settings\n",
        "# @markdown These settings control the core transcription performance and quality.\n",
        "# @markdown **Model Size:** This is the primary trade-off between **speed** and **accuracy**.\n",
        "model_size = 'large-v2' #@param ['large-v2', 'medium', 'small', 'base', 'tiny']\n",
        "# @markdown **Use FP16 Precision:** Using FP16 on a GPU can **double transcription speed**. `auto` is recommended.\n",
        "use_fp16 = 'auto' #@param ['auto', 'True', 'False']\n",
        "# @markdown **Beam Size:** Higher values are more accurate but slower. `5` is a good default.\n",
        "beam_size = 10 #@param {type:\"integer\"}\n",
        "# @markdown **Pause Threshold (seconds):** The length of silence that will create a new paragraph.\n",
        "pause_threshold = 0.3 #@param {type:\"number\"}\n",
        "# @markdown **Max Audio Duration (seconds):** A safeguard to reject excessively long files. Set to `0` to disable.\n",
        "MAX_AUDIO_DURATION_SECONDS = 5400 #@param {type:\"integer\"}\n",
        "# @markdown ---\n",
        "# @markdown ### ‚è≥ Idle Monitor & Auto-Shutdown\n",
        "# @markdown These settings control the automatic shutdown feature to conserve Google Colab compute units.\n",
        "# @markdown **Notify Time (minutes):** Time in minutes of inactivity before the first webhook notification.\n",
        "IDLE_NOTIFY_MIN = 5 #@param {type:\"integer\"}\n",
        "# @markdown **Warning Time (minutes):** Time in minutes of inactivity before the final warning.\n",
        "IDLE_WARN_MIN = 8 #@param {type:\"integer\"}\n",
        "# @markdown **Shutdown Time (minutes):** Time in minutes of inactivity before automatic shutdown.\n",
        "IDLE_SHUTDOWN_MIN = 10 #@param {type:\"integer\"}\n",
        "# @markdown ---\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# SECTION 2: INSTALLATION & IMPORTS\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"‚è≥ Installing required libraries...\")\n",
        "!pip install -q openai-whisper ffmpeg-python numpy torch discord.py==2.3.2 nest_asyncio requests werkzeug\n",
        "print(\"‚úÖ Libraries installed successfully.\")\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "print(\"‚úÖ nest_asyncio applied.\")\n",
        "\n",
        "import discord\n",
        "from discord.ext import commands, tasks\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import asyncio\n",
        "import torch\n",
        "import ffmpeg\n",
        "import whisper\n",
        "import requests\n",
        "import re\n",
        "import zipfile\n",
        "import uuid\n",
        "from collections import defaultdict\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "UPLOAD_FOLDER = 'uploads'\n",
        "TRANSCRIPT_FOLDER = 'transcripts'\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "os.makedirs(TRANSCRIPT_FOLDER, exist_ok=True)\n",
        "print(\"‚úÖ Static paths created.\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# SECTION 3: HARDWARE & MODEL LOADING\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"ü§ñ Checking hardware and loading Whisper model...\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if device == \"cuda\":\n",
        "    print(\"‚úÖ GPU (CUDA) detected!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è GPU (CUDA) not detected. Using CPU. Transcription will be very slow.\")\n",
        "\n",
        "fp16_enabled = False\n",
        "if use_fp16.lower() == 'true':\n",
        "    fp16_enabled = True\n",
        "elif use_fp16.lower() == 'auto' and device == 'cuda':\n",
        "    fp16_enabled = True\n",
        "    print(\"‚úÖ Auto-FP16 enabled for CUDA device.\")\n",
        "\n",
        "model = None\n",
        "try:\n",
        "    print(f\"‚è≥ Loading Whisper model '{model_size}' onto {device.upper()} (FP16: {fp16_enabled})...\")\n",
        "    model = whisper.load_model(model_size, device=device)\n",
        "    print(f\"‚úÖ Whisper model '{model_size}' loaded successfully.\")\n",
        "except Exception as e:\n",
        "    error_msg = f\"‚ùå FAILED to load Whisper model: {e}\"\n",
        "    print(error_msg)\n",
        "    requests.post(DISCORD_WEBHOOK_URL, json={'content': f\"‚ùå **ERROR:** Failed to load Whisper model. Bot cannot start.\\n`{e}`\"})\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# SECTION 4: CORE UTILITIES & CLASSES\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"üèõÔ∏è Defining core architecture classes and utilities...\")\n",
        "\n",
        "def send_webhook_notification(webhook_url, message):\n",
        "    try:\n",
        "        requests.post(webhook_url, json={'content': message})\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not send webhook notification: {e}\")\n",
        "\n",
        "def format_duration(seconds: float) -> str:\n",
        "    if not isinstance(seconds, (int, float)) or seconds < 0: return \"N/A\"\n",
        "    minutes = int(seconds // 60)\n",
        "    remaining_seconds = int(seconds % 60)\n",
        "    return f\"{minutes}m {remaining_seconds:02d}s\"\n",
        "\n",
        "def format_transcription_with_pauses(result: dict, pause_thresh: float) -> str:\n",
        "    formatted_text, previous_end = \"\", 0.0\n",
        "    if \"segments\" not in result: return \"\"\n",
        "    for segment in result[\"segments\"]:\n",
        "        start, text = segment[\"start\"], segment[\"text\"].strip()\n",
        "        if (start - previous_end) > pause_thresh: formatted_text += \"\\n\\n\"\n",
        "        formatted_text += text + \" \"\n",
        "        previous_end = segment.get(\"end\", start + 5.0)\n",
        "    return formatted_text.strip()\n",
        "\n",
        "@dataclass\n",
        "class TranscriptionJob:\n",
        "    message: discord.Message\n",
        "    original_filename: str\n",
        "    local_filepath: str\n",
        "    audio_duration: float\n",
        "    author: discord.Member = field(init=False)\n",
        "    job_id: str = field(default_factory=lambda: uuid.uuid4().hex[:8])\n",
        "    status: str = \"queued\"\n",
        "    def __post_init__(self):\n",
        "        self.author = self.message.author\n",
        "        print(f\"[JOB: {self.job_id}] New job object created for '{self.original_filename}'.\")\n",
        "\n",
        "class JobManager:\n",
        "    def __init__(self, bot: commands.Bot):\n",
        "        self.bot = bot\n",
        "        self.job_queue = asyncio.Queue()\n",
        "        self.active_jobs = {}\n",
        "        print(\"‚úÖ JobManager initialized.\")\n",
        "    async def add_job(self, job: TranscriptionJob):\n",
        "        self.active_jobs[job.job_id] = job\n",
        "        await self.job_queue.put(job)\n",
        "        queue_position = self.job_queue.qsize()\n",
        "        content = f\"‚úÖ `[ID: {job.job_id}]` Your file `{job.original_filename}` has been added to the queue (Position: **#{queue_position}**).\"\n",
        "        await job.message.channel.send(content)\n",
        "        print(f\"[JOB: {job.job_id}] Added to queue at position {queue_position}.\")\n",
        "    def complete_job(self, job_id: str):\n",
        "        if job_id in self.active_jobs:\n",
        "            del self.active_jobs[job_id]\n",
        "            print(f\"[JOB: {job_id}] Job completed and removed from active list.\")\n",
        "    def is_idle(self) -> bool:\n",
        "        return self.job_queue.empty() and not self.active_jobs\n",
        "\n",
        "class IdleMonitor:\n",
        "    def __init__(self, bot: commands.Bot, job_manager: JobManager, webhook_url: str):\n",
        "        self.bot = bot\n",
        "        self.job_manager = job_manager\n",
        "        self.webhook_url = webhook_url\n",
        "        self._last_activity_time = time.time()\n",
        "        self._notifications_sent = set()\n",
        "        self.check_idle_status.start()\n",
        "        print(f\"‚úÖ IdleMonitor initialized. Settings: Notify={IDLE_NOTIFY_MIN}m, Warn={IDLE_WARN_MIN}m, Shutdown={IDLE_SHUTDOWN_MIN}m.\")\n",
        "    def reset_timer(self):\n",
        "        if self._notifications_sent: print(\"[IDLE_MONITOR] Activity detected. Resetting idle timer.\")\n",
        "        self._last_activity_time = time.time()\n",
        "        self._notifications_sent.clear()\n",
        "\n",
        "    async def _initiate_shutdown(self):\n",
        "        print(f\"[IDLE_MONITOR] {IDLE_SHUTDOWN_MIN}-minute idle limit reached. Initiating shutdown.\")\n",
        "        shutdown_message = (f\"üî¥ **AUTO-SHUTDOWN:** Bot has been idle for {IDLE_SHUTDOWN_MIN} minutes. \"\n",
        "                            f\"Terminating Colab runtime to save resources.\")\n",
        "        send_webhook_notification(self.webhook_url, shutdown_message)\n",
        "        await perform_shutdown(self.bot)\n",
        "\n",
        "    @tasks.loop(minutes=1)\n",
        "    async def check_idle_status(self):\n",
        "        if not self.job_manager.is_idle():\n",
        "            self.reset_timer()\n",
        "            return\n",
        "        idle_minutes = (time.time() - self._last_activity_time) / 60\n",
        "        if idle_minutes >= IDLE_SHUTDOWN_MIN and IDLE_SHUTDOWN_MIN not in self._notifications_sent:\n",
        "            self._notifications_sent.add(IDLE_SHUTDOWN_MIN)\n",
        "            await self._initiate_shutdown()\n",
        "            self.check_idle_status.stop()\n",
        "            return\n",
        "        if idle_minutes >= IDLE_WARN_MIN and IDLE_WARN_MIN not in self._notifications_sent:\n",
        "            self._notifications_sent.add(IDLE_WARN_MIN)\n",
        "            print(f\"[IDLE_MONITOR] {IDLE_WARN_MIN}-minute idle warning.\")\n",
        "            send_webhook_notification(self.webhook_url, f\"‚ö†Ô∏è **IDLE WARNING:** No activity for {IDLE_WARN_MIN} minutes. Bot will shut down in {IDLE_SHUTDOWN_MIN - IDLE_WARN_MIN} minutes.\")\n",
        "        if idle_minutes >= IDLE_NOTIFY_MIN and IDLE_NOTIFY_MIN not in self._notifications_sent:\n",
        "            self._notifications_sent.add(IDLE_NOTIFY_MIN)\n",
        "            print(f\"[IDLE_MONITOR] {IDLE_NOTIFY_MIN}-minute idle notification.\")\n",
        "            send_webhook_notification(self.webhook_url, f\"‚ÑπÔ∏è **IDLE NOTIFICATION:** No activity for {IDLE_NOTIFY_MIN} minutes. Bot will shut down in {IDLE_SHUTDOWN_MIN - IDLE_NOTIFY_MIN} minutes if it remains idle.\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# SECTION 5: FILE HANDLING & VALIDATION\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"üìÅ Setting up file handling and validation logic...\")\n",
        "\n",
        "class FilesHandler:\n",
        "    def __init__(self, job_manager: JobManager, upload_folder: str):\n",
        "        self.job_manager = job_manager\n",
        "        self.upload_folder = upload_folder\n",
        "        self.chunk_regex = re.compile(r'\\.zip\\.\\d{3}$')\n",
        "        print(\"‚úÖ FilesHandler initialized.\")\n",
        "    async def _validate_and_queue_file(self, local_path: str, original_filename: str, message: discord.Message):\n",
        "        temp_job_id = uuid.uuid4().hex[:8]\n",
        "        print(f\"[VALIDATE:{temp_job_id}] Starting validation for '{original_filename}'...\")\n",
        "        try:\n",
        "            probe = await asyncio.to_thread(ffmpeg.probe, local_path)\n",
        "            duration = float(probe['format']['duration'])\n",
        "            print(f\"[VALIDATE:{temp_job_id}] ffmpeg probe successful. Duration: {duration:.2f}s.\")\n",
        "            max_duration = int(MAX_AUDIO_DURATION_SECONDS)\n",
        "            if max_duration > 0 and duration > max_duration:\n",
        "                error_msg = f\"File duration ({format_duration(duration)}) exceeds the max allowed ({format_duration(max_duration)}).\"\n",
        "                print(f\"‚ùå [VALIDATE:{temp_job_id}] FAILED: {error_msg}\")\n",
        "                await message.reply(f\"‚ùå Could not process `{original_filename}`. **Reason:** {error_msg}\")\n",
        "                os.remove(local_path)\n",
        "                return\n",
        "            job = TranscriptionJob(message, original_filename, local_path, duration)\n",
        "            await self.job_manager.add_job(job)\n",
        "        except ffmpeg.Error as e:\n",
        "            err_details = e.stderr.decode('utf-8') if e.stderr else 'Unknown ffmpeg error'\n",
        "            print(f\"‚ùå [VALIDATE:{temp_job_id}] FAILED: ffmpeg could not probe file. Error: {err_details}\")\n",
        "            await message.reply(f\"‚ùå Could not process `{original_filename}`. It may be corrupted or an unsupported media file.\")\n",
        "            os.remove(local_path)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå [VALIDATE:{temp_job_id}] FAILED: An unexpected error occurred. Error: {e}\")\n",
        "            await message.reply(f\"‚ùå An unexpected error occurred while validating `{original_filename}`.\")\n",
        "            if os.path.exists(local_path): os.remove(local_path)\n",
        "    async def handle_attachments(self, message: discord.Message):\n",
        "        chunks = defaultdict(list)\n",
        "        other_files = []\n",
        "        for att in message.attachments:\n",
        "            if self.chunk_regex.search(att.filename):\n",
        "                base_name = att.filename.rsplit('.zip.', 1)[0]\n",
        "                chunks[base_name].append(att)\n",
        "            else: other_files.append(att)\n",
        "        for base_name, chunk_list in chunks.items(): await self._process_chunk_group(f\"{base_name}.zip\", chunk_list, message)\n",
        "        for att in other_files: await self._process_single_attachment(att, message)\n",
        "    async def _process_chunk_group(self, final_zip_name: str, chunk_list: list, message: discord.Message):\n",
        "        chunk_list.sort(key=lambda x: x.filename)\n",
        "        status_msg = await message.channel.send(f\"üß© Merging **{len(chunk_list)}** parts for `{final_zip_name}`...\")\n",
        "        combined_zip_path = os.path.join(self.upload_folder, f\"{int(time.time())}_{secure_filename(final_zip_name)}\")\n",
        "        try:\n",
        "            with open(combined_zip_path, 'wb') as dest_file:\n",
        "                for chunk_att in chunk_list:\n",
        "                    temp_chunk_path = os.path.join(self.upload_folder, chunk_att.filename)\n",
        "                    await chunk_att.save(temp_chunk_path)\n",
        "                    with open(temp_chunk_path, 'rb') as src_file: shutil.copyfileobj(src_file, dest_file)\n",
        "                    os.remove(temp_chunk_path)\n",
        "            await status_msg.edit(content=f\"üóúÔ∏è Extracting files from merged `{final_zip_name}`...\")\n",
        "            await self._extract_and_queue_zip(combined_zip_path, final_zip_name, message)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to merge chunks for `{final_zip_name}`: {e}\")\n",
        "            await message.channel.send(f\"‚ùå Failed to merge chunks for `{final_zip_name}`: `{e}`\")\n",
        "        finally:\n",
        "            if os.path.exists(combined_zip_path): os.remove(combined_zip_path)\n",
        "    async def _process_single_attachment(self, attachment: discord.Attachment, message: discord.Message):\n",
        "        local_path = os.path.join(self.upload_folder, f\"{int(time.time())}_{secure_filename(attachment.filename)}\")\n",
        "        await attachment.save(local_path)\n",
        "        if attachment.filename.lower().endswith('.zip'):\n",
        "            await message.channel.send(f\"üóúÔ∏è Extracting files from `{attachment.filename}`...\")\n",
        "            await self._extract_and_queue_zip(local_path, attachment.filename, message)\n",
        "            os.remove(local_path)\n",
        "        else: await self._validate_and_queue_file(local_path, attachment.filename, message)\n",
        "    async def _extract_and_queue_zip(self, zip_path: str, original_zip_name: str, message: discord.Message):\n",
        "        extract_dir = os.path.join(self.upload_folder, f\"extract_{int(time.time())}\")\n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                await asyncio.to_thread(zip_ref.extractall, extract_dir)\n",
        "            for root, _, files in os.walk(extract_dir):\n",
        "                for filename in files:\n",
        "                    if not filename.startswith('__MACOSX') and not filename.startswith('.'):\n",
        "                        source_path, dest_path = os.path.join(root, filename), os.path.join(self.upload_folder, f\"{int(time.time())}_{secure_filename(filename)}\")\n",
        "                        shutil.move(source_path, dest_path)\n",
        "                        await self._validate_and_queue_file(dest_path, filename, message)\n",
        "        except zipfile.BadZipFile:\n",
        "            print(f\"‚ö†Ô∏è Bad zip file uploaded: {original_zip_name}\")\n",
        "            await message.reply(f\"‚ùå Failed to extract `{original_zip_name}`: Corrupted or invalid ZIP archive.\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error extracting zip `{original_zip_name}`: {e}\")\n",
        "            await message.reply(f\"‚ùå An unexpected error occurred while extracting `{original_zip_name}`: `{e}`\")\n",
        "        finally:\n",
        "            if os.path.exists(extract_dir): shutil.rmtree(extract_dir)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# SECTION 6: DISCORD BOT & WORKER\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"ü§ñ Initializing Discord bot and background worker...\")\n",
        "intents = discord.Intents.default()\n",
        "intents.message_content = True\n",
        "bot = commands.Bot(command_prefix=\"!\", intents=intents)\n",
        "job_manager = JobManager(bot)\n",
        "files_handler = FilesHandler(job_manager, UPLOAD_FOLDER)\n",
        "idle_monitor: Optional[IdleMonitor] = None\n",
        "\n",
        "def run_transcription_process(job: TranscriptionJob) -> tuple[str, str]:\n",
        "    print(f\"[JOB: {job.job_id}] Starting transcription for '{job.original_filename}'. Using FP16: {fp16_enabled}, Beam Size: {beam_size}\")\n",
        "    transcribe_options = {\"fp16\": fp16_enabled, \"word_timestamps\": True}\n",
        "    if beam_size > 0: transcribe_options[\"beam_size\"] = beam_size\n",
        "    result = model.transcribe(job.local_filepath, **transcribe_options)\n",
        "    formatted_text = format_transcription_with_pauses(result, pause_threshold)\n",
        "    base_name = os.path.splitext(job.original_filename)[0]\n",
        "    safe_name = secure_filename(base_name)[:50]\n",
        "    duration_str = format_duration(job.audio_duration).replace(\" \", \"\")\n",
        "    output_filename = f\"TS_({duration_str})_{safe_name}.txt\"\n",
        "    output_filepath = os.path.join(TRANSCRIPT_FOLDER, output_filename)\n",
        "    with open(output_filepath, \"w\", encoding=\"utf-8\") as f: f.write(formatted_text)\n",
        "    detected_language = result.get('language', 'N/A')\n",
        "    print(f\"[JOB: {job.job_id}] Transcription complete. Output: '{output_filepath}'. Language: {detected_language.upper()}.\")\n",
        "    return output_filepath, detected_language\n",
        "\n",
        "async def queue_processor(manager: JobManager):\n",
        "    await bot.wait_until_ready()\n",
        "    while not bot.is_closed():\n",
        "        job: TranscriptionJob = await manager.job_queue.get()\n",
        "        local_transcript_path = None\n",
        "        try:\n",
        "            job.status = \"processing\"\n",
        "            duration_str = format_duration(job.audio_duration)\n",
        "            await job.message.channel.send(f\"‚ñ∂Ô∏è `[ID: {job.job_id}]` Now processing `{job.original_filename}` (Duration: **{duration_str}**)...\")\n",
        "            print(f\"[JOB: {job.job_id}] Status updated to 'processing'.\")\n",
        "            local_transcript_path, detected_lang = await asyncio.to_thread(run_transcription_process, job)\n",
        "            embed = discord.Embed(title=\"üéâ Transcription Complete!\", color=discord.Color.green())\n",
        "            embed.add_field(name=\"Original File\", value=f\"`{job.original_filename}`\", inline=False)\n",
        "            embed.add_field(name=\"Audio Duration\", value=format_duration(job.audio_duration), inline=True)\n",
        "            embed.add_field(name=\"Detected Language\", value=detected_lang.upper(), inline=True)\n",
        "            embed.set_footer(text=f\"Processed for {job.author.display_name} | Job ID: {job.job_id}\")\n",
        "            await job.message.reply(embed=embed, file=discord.File(local_transcript_path))\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå [JOB: {job.job_id}] FATAL ERROR during processing: {e}\")\n",
        "            error_embed = discord.Embed(\n",
        "                title=f\"‚ùå Failed to Process: {job.original_filename}\",\n",
        "                description=f\"An unexpected error occurred during transcription.\\n```\\n{e}\\n```\",\n",
        "                color=discord.Color.red())\n",
        "            error_embed.set_footer(text=f\"Job ID: {job.job_id}\")\n",
        "            await job.message.reply(embed=error_embed)\n",
        "        finally:\n",
        "            if os.path.exists(job.local_filepath): os.remove(job.local_filepath)\n",
        "            if local_transcript_path and os.path.exists(local_transcript_path): os.remove(local_transcript_path)\n",
        "            manager.job_queue.task_done()\n",
        "            manager.complete_job(job.job_id)\n",
        "\n",
        "@bot.event\n",
        "async def on_ready():\n",
        "    global idle_monitor\n",
        "    print('----------------------------------------------------')\n",
        "    print(f'‚úÖ Bot has logged in as {bot.user}')\n",
        "    print(f'üöÄ Worker queue started. Bot active in Channel ID: {DISCORD_CHANNEL_ID}')\n",
        "    print('----------------------------------------------------')\n",
        "    bot.loop.create_task(queue_processor(job_manager))\n",
        "    idle_monitor = IdleMonitor(bot, job_manager, DISCORD_WEBHOOK_URL)\n",
        "\n",
        "@bot.event\n",
        "async def on_message(message: discord.Message):\n",
        "    if message.author.bot or str(message.channel.id) != DISCORD_CHANNEL_ID: return\n",
        "    await bot.process_commands(message)\n",
        "    if message.attachments:\n",
        "        if idle_monitor: idle_monitor.reset_timer()\n",
        "        bot.loop.create_task(files_handler.handle_attachments(message))\n",
        "\n",
        "@bot.command(name=\"ping\", help=\"Checks bot latency, queue, and idle status.\")\n",
        "async def ping(ctx: commands.Context):\n",
        "    latency = round(bot.latency * 1000)\n",
        "    queue_size = job_manager.job_queue.qsize()\n",
        "    embed = discord.Embed(title=\"üìä Bot Status & Health\", color=discord.Color.green())\n",
        "    embed.add_field(name=\"Network Latency\", value=f\"**{latency}ms**\", inline=True)\n",
        "    embed.add_field(name=\"Jobs in Queue\", value=f\"**{queue_size}**\", inline=True)\n",
        "    if not job_manager.is_idle() or not idle_monitor:\n",
        "        embed.add_field(name=\"Status\", value=\"‚úÖ **Active** (Processing or has jobs in queue)\", inline=False)\n",
        "    else:\n",
        "        idle_duration = time.time() - idle_monitor._last_activity_time\n",
        "        notify_sec, warn_sec, shutdown_sec = IDLE_NOTIFY_MIN * 60, IDLE_WARN_MIN * 60, IDLE_SHUTDOWN_MIN * 60\n",
        "        if idle_duration >= warn_sec:\n",
        "            embed.color, status_msg = discord.Color.orange(), \"‚ö†Ô∏è **Warning**\"\n",
        "            next_action_msg = f\"Auto-shutdown in **{format_duration(max(0, shutdown_sec - idle_duration))}**\"\n",
        "        elif idle_duration >= notify_sec:\n",
        "            embed.color, status_msg = discord.Color.gold(), f\"‚ÑπÔ∏è **Notified**\"\n",
        "            next_action_msg = f\"Final warning in **{format_duration(warn_sec - idle_duration)}**\"\n",
        "        else:\n",
        "            embed.color, status_msg = discord.Color.blue(), \"üïí **Idle**\"\n",
        "            next_action_msg = f\"First notification in **{format_duration(notify_sec - idle_duration)}**\"\n",
        "        embed.add_field(name=\"Status\", value=status_msg, inline=False)\n",
        "        embed.add_field(name=\"Time Idle\", value=f\"{format_duration(idle_duration)}\", inline=True)\n",
        "        embed.add_field(name=\"Next Action\", value=next_action_msg, inline=True)\n",
        "    embed.set_footer(text=f\"Requested by {ctx.author.display_name}\")\n",
        "    await ctx.send(embed=embed)\n",
        "\n",
        "async def perform_shutdown(bot_instance: commands.Bot):\n",
        "    \"\"\"The core shutdown logic: clean up, close connection, and terminate.\"\"\"\n",
        "    print(\"üßπ Cleaning up temporary folders...\")\n",
        "    if os.path.exists(UPLOAD_FOLDER): shutil.rmtree(UPLOAD_FOLDER)\n",
        "    if os.path.exists(TRANSCRIPT_FOLDER): shutil.rmtree(TRANSCRIPT_FOLDER)\n",
        "    print(\"‚úÖ Cleanup complete.\")\n",
        "    print(\"üõë Closing bot connection...\")\n",
        "    await bot_instance.close()\n",
        "    print(\"üîå Terminating Colab runtime...\")\n",
        "    runtime.unassign()\n",
        "\n",
        "# --- THIS IS THE CORRECTED SHUTDOWN COMMAND ---\n",
        "@bot.command(name=\"shutdown\", help=\"Shuts down the bot and the Colab runtime.\")\n",
        "async def shutdown(ctx: commands.Context):\n",
        "    \"\"\"Sends a confirmation message to the channel, then safely shuts down the bot.\"\"\"\n",
        "    # 1. Send an immediate confirmation message to the channel where the command was used.\n",
        "    await ctx.send(f\"üî¥ **MANUAL SHUTDOWN:** Command received from **{ctx.author.display_name}**. Bot is now shutting down...\")\n",
        "\n",
        "    # 2. Call the generic function to perform the actual shutdown sequence.\n",
        "    await perform_shutdown(bot)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# SECTION 7: RUN THE BOT\n",
        "# ------------------------------------------------------------------------------\n",
        "if model:\n",
        "    max_dur_str = format_duration(MAX_AUDIO_DURATION_SECONDS) if MAX_AUDIO_DURATION_SECONDS > 0 else \"Unlimited\"\n",
        "    startup_message = (\n",
        "        f\"‚úÖ **Colab Runtime Ready!**\\n\"\n",
        "        f\"Model: **{model_size}** on **{device.upper()}** | \"\n",
        "        f\"FP16: **{fp16_enabled}** | Beam Size: **{beam_size}**\\n\"\n",
        "        f\"Pause Threshold: **{pause_threshold}s** | Max Duration: **{max_dur_str}**.\\n\"\n",
        "        f\"Bot is starting... Idle monitor is **active**.\"\n",
        "    )\n",
        "    send_webhook_notification(DISCORD_WEBHOOK_URL, startup_message)\n",
        "    print(\"\\n‚ñ∂Ô∏è Running bot...\")\n",
        "    try:\n",
        "        bot.run(DISCORD_BOT_TOKEN)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå CRITICAL ERROR: FAILED to run bot: {e}\")\n",
        "        send_webhook_notification(DISCORD_WEBHOOK_URL, f\"‚ùå **CRITICAL ERROR:** Bot failed to run.\\n`{e}`\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Bot cannot run because the Whisper model failed to load. Please check previous logs.\")"
      ],
      "metadata": {
        "id": "L1bb9OEI43VO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}